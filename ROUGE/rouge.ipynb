{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install rouge-metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textrank dict\n",
    "%run ../textrank/textrank.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lexrank dict\n",
    "%run ../lexrank/lexrank.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for 'red_txt' method\n",
    "%run ../rfej_preprocessing/find_shortenings.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROUGE algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Путь к файлам с аннотациями\n",
    "PATH = os.path.abspath('..\\\\rfej_parser\\\\articles\\\\') + '\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rouge_metric import PyRouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort file names\n",
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "def join_text_annotation() -> list:\n",
    "    # supress 'WARNING:root:Something went wrong while tokenizing'\n",
    "    logging.root.level = logging.ERROR\n",
    "\n",
    "    annot = []\n",
    "    files = [fname for fname in glob.glob(PATH + \"*\") if re.match(f\".*\\\\d+.txt$\", fname)]\n",
    "    files.sort(key=natural_keys)\n",
    "    for f in files:\n",
    "        sent_ann = ['\\n'.join(sentence_collection(read_txt(f)))]\n",
    "        annot.append(sent_ann)\n",
    "        \n",
    "    logging.root.level = logging.WARNING\n",
    "    return annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def join_text_summary(summary: dict, type_sum: str) -> dict:\n",
    "    \"\"\" \n",
    "    Reformat dict for ROUGE method standart.\n",
    "        type_sum: lexrank -> 'l', textrank -> 't'.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    summary = dict(sorted(summary.items()))\n",
    "    for nb in summary:\n",
    "        result[nb] = '\\n'.join(\n",
    "            summary[nb] if type_sum == 't' else [str(sent) for sent in summary[nb]]\n",
    "        ).lower()\n",
    "#         result[nb] = re.sub(r'[^\\w]', ' ', result[nb])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ROUGE METRIC CALCULATION\n",
    "def rouge_alg(summary: dict, references: list) -> dict:\n",
    "    # Load summary results\n",
    "    hypotheses = []\n",
    "    for nb in summary:\n",
    "        hypotheses.append(summary[nb])\n",
    "    # Evaluate document-wise ROUGE scores\n",
    "    rouge = PyRouge(rouge_n=(1, 2), rouge_l=True, mode='average')\n",
    "    scores = rouge.evaluate(hypotheses, references)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "annotations = join_text_annotation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hypotheses_textrank = join_text_summary(sum_textrank, 't')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hypotheses_lexrank = join_text_summary(sum_lexrank, 'l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ROUGE for TextRank\n",
    "metrics_textrank = rouge_alg(hypotheses_textrank, annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ROUGE for LexRank\n",
    "metrics_lexrank = rouge_alg(hypotheses_lexrank, annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'f': 0.14106136813929335,\n",
       "  'p': 0.1232744008653751,\n",
       "  'r': 0.1648467030676705},\n",
       " 'rouge-2': {'f': 0.02208817713994442,\n",
       "  'p': 0.018807195458214607,\n",
       "  'r': 0.026755825390976602},\n",
       " 'rouge-l': {'f': 0.13044844876831158,\n",
       "  'p': 0.11427454976768742,\n",
       "  'r': 0.15195554396767527}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# По метрикам rouge-1, rouge-l TextRank лучше (8 предложений на summary)\n",
    "metrics_textrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'f': 0.13181783467116304,\n",
       "  'p': 0.08159462030314618,\n",
       "  'r': 0.3428480760925167},\n",
       " 'rouge-2': {'f': 0.032980495952016624,\n",
       "  'p': 0.02013056627145094,\n",
       "  'r': 0.09118928697231742},\n",
       " 'rouge-l': {'f': 0.11904164997049979,\n",
       "  'p': 0.07374374521991428,\n",
       "  'r': 0.3086067052737675}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_lexrank"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
