{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run converter.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from lxml import html\n",
    "import urllib\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "from docx.api import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_annotation(doc_name: str) -> str:\n",
    "    \"\"\"Parse paragraphs in docx. Return annotation.\n",
    "    \"\"\"\n",
    "    doc = Document(os.path.abspath('./articles/' + doc_name + '.docx'))\n",
    "    tmp = ''\n",
    "    annotation = ''\n",
    "    ann_flag = 0\n",
    "    for para in doc.paragraphs:\n",
    "        if tmp.strip() == 'Аннотация' and not ann_flag:\n",
    "            ann_flag = 1\n",
    "        if ann_flag:\n",
    "            if para.text.find('Ключевые слова') != -1:\n",
    "                break\n",
    "            annotation += para.text\n",
    "        tmp = para.text\n",
    "    return annotation\n",
    "\n",
    "def download(url: str, annotation: str):\n",
    "    \"\"\"Download article and annotation from 'url' to directory 'articles'. \n",
    "    If folder doesn't exist, create it. Name file by its number.    \n",
    "    \"\"\"\n",
    "    download.name += 1\n",
    "    url = urllib.parse.quote(url)\n",
    "    Path(\"./articles\").mkdir(parents=True, exist_ok=True)\n",
    "    urllib.request.urlretrieve(\n",
    "        'http://www.rfej.ru' + url, './articles/{}.pdf'.format(download.name))\n",
    "    to_del = conv.pdf_to_docx(str(download.name))  # convert to .docx\n",
    "    os.remove(to_del)  # delete .pdf\n",
    "    pdf_ann = get_annotation(str(download.name))\n",
    "    if pdf_ann:  # if annotation is inside .pdf\n",
    "        annotation = pdf_ann\n",
    "    f = open('./articles/{}.txt'.format(download.name), \"w\", encoding='utf-8') \n",
    "    f.write(annotation) \n",
    "    f.close()\n",
    "download.name = 0  # var for file names\n",
    "\n",
    "def parse_articles(page_id: str):\n",
    "    page = requests.get('http://www.rfej.ru{}'.format(page_id))\n",
    "    webpage = html.fromstring(page.content)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    a = soup.find_all('p', attrs={'class': 'sanno'})\n",
    "    pdf_url = list(set(webpage.xpath(\"//a[contains(@href, '.pdf')]/@href\")))\n",
    "    if pdf_url and a[0].text:\n",
    "        download(pdf_url[0], a[0].text)\n",
    "\n",
    "def parse_months(month: str):\n",
    "    page = requests.get('http://www.rfej.ru{}'.format(month))\n",
    "    webpage = html.fromstring(page.content)\n",
    "    for el in set(webpage.xpath(\"//a[starts-with(@href, '/rvv/id')]/@href\")):\n",
    "        parse_articles(el)\n",
    "\n",
    "def parse_years(year: str):\n",
    "    page = requests.get('http://www.rfej.ru{}'.format(year))\n",
    "    webpage = html.fromstring(page.content)\n",
    "    for el in set(webpage.xpath(\"//a[starts-with(@href, '/rvv/years/month')]/@href\")):\n",
    "        parse_months(el)\n",
    "\n",
    "def parse():\n",
    "    \"\"\"Function parses in cycle every year/month/article page and downloads\n",
    "    all articles and annotations from this pages. \n",
    "    \"\"\"\n",
    "    page = requests.get('http://www.rfej.ru/rvv/years')\n",
    "    webpage = html.fromstring(page.content)\n",
    "    for el in webpage.xpath(\n",
    "        \"//a[starts-with(@href, '/rvv/years/by') and text()>='2012']/@href\"):\n",
    "        parse_years(el)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv = Converter()\n",
    "parse() # start parsing and downloading\n",
    "del conv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
